\documentclass{article}
\usepackage{amsmath}
\usepackage[a4paper,margin=60pt]{geometry}
\setlength{\parindent}{0pt} %no first line of paragraph auto-indent
\pagenumbering{roman}

\begin{document}
\title{FAB\textbackslash HME\quad Multi-target}
\author{NEC\ Labs\ China}
\maketitle

\section{Preliminaries}
\subsection{Data matrix}
\begin{description}
\item[(1)] $X\in R^{m\times n} $
\item[(2)] $Y\in R^{k\times n} $
\item[(3)] $n$ indicates $n$ samples, for each there are $m$ features, and $k$ targets
\end{description}

\subsection{Latent variables}
\begin{description}
\item[(1)] $ \zeta_j^n \in \{ 0,1\} $ is latent variable related to the $j$ -th path
\item[(2)] $ \phi = \{\Theta_{yy} ,\Theta_{xy}\}$ is inverse covariance matrix, 
	where $\begin{pmatrix} 	\Theta_{xx} & \Theta_{xy} \\
		\Theta_{xy}^T & \Theta_{yy}
	\end{pmatrix} = \Sigma^{-1} = \begin{pmatrix}
	\Sigma_{xx} & \Sigma_{xy} \\
	\Sigma_{xy}^T & \Sigma_{yy}
	\end{pmatrix}^{-1}$ , and \\ $ \begin{pmatrix}
	\textbf{x}_i  \\
	\textbf{y}_i 
	\end{pmatrix} \sim N\left(\begin{pmatrix}
	\textbf{0}_M  \\
	\textbf{0}_K 
	\end{pmatrix}, \Sigma\right) $
	\end{description}

\subsection{Distribution of latent variables}

$$ p(\zeta^N|x^N,\beta;\gamma)=
	\prod_{n=1}^{N}
	\prod_{j=1}^E
	\prod_{i \in \epsilon_j}
		{\psi_g(x^{(n)},i,j)^{\zeta_j^{(n)}}} $$ 
		
\begin{description}
\setlength{\itemindent}{20em}
\item $ \psi_g(x,i,j):=\psi(g(x,\alpha_i),i,j) $ \\
\item $ \psi(a,i,j):= \begin{cases}
		a & \mbox{if the j is in the left sub-tree of i} \\
		1-a & \mbox{otherwise}
	\end{cases} $
\end{description}

\subsection{Joint distribution}

\begin{align*}
p(y^N,\zeta^N|x^N,\theta) & = p(y^N|x^N,\zeta^N,\phi)p(\zeta^N|x^N,\beta) \\
	& = \prod_{n=1}^N \prod_{j=1}^{E} p(y_n|x_n,\phi_j)^{\zeta_j^n}
		\prod_{n=1}^{N}
		\prod_{j=1}^E
		\prod_{i \in \epsilon_j}
		{\psi_g(x_n,i,j)^{\zeta_j}}
\end{align*} 

%$$ p(y_n|x_n,\theta;\gamma)=\sum_{j=1}^E\prod_{i \in \epsilon_j}
%	\psi_g(x,i,j)p(y|x,\phi_j)$$ \\
\hspace*{25em} HME Model, $ \theta = (\beta_1,...,\beta_G,\phi_1,...,\phi_E) $
%In $c$-th component:\\
$$ p(y_n|x_n,\phi_j)=\frac
	{\exp{(-1/2y_n^T\Theta_{yy}y_n - x_n^T\Theta_{xy}y_n)}}
	{\sqrt{(2\pi)^K/\det\Theta_{yy}}
		\exp{(1/2x_n^T\Theta_{xy}\Theta_{yy}^{-1}\Theta_{xy}^Tx_n)}}$$ \\
\hspace*{25em} conditional Gaussian graphical model (CGGM) \\
\hspace*{25em} i.e. $y_i|x_i \sim N(-\Theta_{yy}^{-1}\Theta_{xy}^Tx_i,\Theta_{yy}^{-1}) $ \\

%$$ p(y_i|x_i,\zeta,\phi) = \sum_{j=1}^{E} p(y_i|x_i,\phi_j)^{\zeta_j^i}  $$ \\

\section{FIC for FAB \textbackslash HME Multi-target}
$$ log\-likelihood=\log{p(y^N|x^N,M)} \\
	\geq\sum_{\zeta^N}q(\zeta^N)log(\frac{p(y^N,\zeta^N|x^N,M)}{q(\zeta^N)}) $$ \\

\begin{align*}
\log{p(y^N,\zeta^N|x^N,M)} & = \log \int{ 
	\prod_{j=1}^Z \prod_{i \in \epsilon_j} p(\zeta^N_j|x^N,\beta_i)
	\prod_{j=1}^{E} p(y^N|x^N,\zeta_j^N,\phi_j) p(\theta|M)d\theta} \\
	& = \log \int{ 
	\prod_{i=1}^G p(\eta^N_i|x^N,\beta_i)
	\prod_{j=1}^{E} p(y^N|x^N,\zeta_j^N,\phi_j) p(\theta|M)d\theta}
\end{align*}
\hspace*{25em} $p(\eta^N_i|x^N,\beta_i) =
	\prod_{j \in G_i} p(\zeta_j^N|x^N,\beta_i) $ \\

\begin{description}
\setlength{\itemindent}{20em}
\item $ \bar{\mathcal{F}}_{G_i} = -\frac{1}{\sum_{n=1}^{N}
	\sum_{j \in \mathcal{G}_i}\zeta_j^{(n)}} 
	\nabla^2 p(\eta_i^N|x^N,\beta_i) \left . \right|_{\beta_i=\bar{\beta_i}} $ \\
\item $ \bar{\mathcal{F}}_{E_j} = -\frac{1}{\sum_{n=1}^{N}\zeta_j^{(n)}}
	\nabla^2 p(y^N|\zeta_i^N,x^N,\phi_j) \left . \right|_{\phi_j=\bar{\phi_j}} $
\end{description}

$$ FIC = \max_q\sum_{\zeta^N}q(\zeta^N)\{
	\log p(y^N,\zeta^N|x^N,\bar{\theta})-
	\sum_{i=1}^{G}\frac{\mathcal{D}_{\beta_i}}{2}
	\log\sum_{n=1}^{N}
	\sum_{j \in \mathcal{G}_i}\zeta_j^{(n)}
	-\sum_{j=1}^{E}\frac{\mathcal{D}_{\phi_j}}{2}
	\log(\sum_{n=1}^{N}\zeta_j^{(n)})
	-\log q(\zeta^N) \} $$
%\end{align*} 

%\begin{description}
%\item $\log p(y,\zeta|x,\theta) $ 
%\item $\mathcal{D}_{\phi_j} $
%\end{description}

\section{FAB for FAB \textbackslash HME Multi-target}
\subsection{FIC lower bound}

\begin{multline*}
FIC_{LB} = \Gamma(q,\tilde{q},\theta,y,x) = \max_q \sum_{\zeta^N} q(\zeta^N) \{
	\log p(y^N,\zeta^N|x^N,\theta) \\
	-\sum_{i=1}^{G} ( \frac{\mathcal{D}_\beta}{2}
		\mathcal{L}(\sum_{n=1}^{N}\sum_{j \in \mathcal{G}_i}\zeta_j^n , 
		\sum_{n=1}^{N}\sum_{j \in \mathcal{G}_i}\tilde{q}(\zeta_j^n)) ) 
	-\sum_{j=1}^{E}\frac{\mathcal{D}_{\phi_j}}{2}
	\mathcal{L}(\sum_{n=1}^{N}\zeta_j^n , \sum_{n=1}^{N}\tilde{q}(\zeta_j^n)) 
	-\log q(\zeta^N) \} 
\end{multline*}

\subsection{E step}
$$ q^{(t)} = \arg\max_q(\Gamma(q,\tilde{q},\theta,y,x)) $$
$$ \nabla_{q(\zeta_j)} FIC_{LB}= 0 $$
$$ q^{(t)}(\zeta_j^{(n)}) \propto \prod_{i \in \epsilon_j} 
	\psi_g^{(t-1)} (x^{(n)},i,j) p(y^{(n)}|x^{(n)},\phi_j^{(t-1)}) 
		\exp \{ \sum_{i \in \epsilon_j} 
			\frac{-D_{\beta_i}}{2N_{\beta_i}^{(t-1)}} +
				\frac{-D_{\phi_j}}{2N_{\phi_i}^{(t-1)}} \} $$ \\
\begin{description}
\setlength{\itemindent}{20em}
\item $ N_{\beta_i}^{(t-1)} = \sum_{n=1}^{N}\sum_{j \in \mathcal{G}_i} 
	q^{(t)} (\zeta_j^{(n)} $ \\
\item $ N_{\phi_i}^{(t-1)} = \sum_{n=1}^{N}	q^{(t)} (\zeta_j^{(n)}) $
\end{description}
				
$ q(\zeta_j) $ updating: \\
\begin{enumerate}
\item initialization: sampling $q$ randomly, get $\phi_j$ 
%for t=1,...,G \\
%\qquad $ q(\zeta_t) = \prod_{i \in \epsilon_j} 
%	\psi_g^{(t-1)} (x^{(n)},i,j) p(y^{(n)}|x^{(n)},\phi_j^{(t-1)}) 
%	\exp \{ \sum_{i \in \epsilon_j} 
%	\frac{-D_{\beta_i}}{2N_{\beta_i}^{(t-1)}} 
%	\frac{-D_{\phi_j}}{2N_{\phi_i}^{(t-1)}} \} $ \\
\item normalization in each round: $ q(\zeta_j) = q(\zeta_j)/\sum_{t=1}^{E} q(\zeta_t) $ \\
\end{enumerate}


\subsection{M step}
For gating nodes: \\
$$ \gamma_i^{(t)},\beta_i^{(t)} = \arg\max_{\gamma_i,\beta_i} 
	\{ \sum_{n=1}^{N}
	\sum_{j \in \mathcal{G}_i}q^{(t)}(\zeta_j^{(n)})
	\log\psi_g^{(t)} (x^{(n)},i,j)
	-\frac{D_{\beta_i}}{2}\log(N_{\beta_i}^{(t)})
	 \} $$ 
	 
For experts: \\
$$ S_j^{(t)}, \phi_j^{(t)} = \arg\max_{S_j,\phi_j}
	\{   \sum_{n=1}^{N}q^{(t)}(\zeta_j^{(n)})
	\log p(y^{(n)} | x^{(n)},\phi_j)
	-\frac{D_{\phi_j}}{2}\log(N_{\phi_j}^{(t)})
	\} $$	 

Feature selection in expert nodes: \\
\begin{description}
\setlength{\itemindent}{5em}
\item $ w_j^{(t)} = \arg\min_{w_j} Q(w_j,(\sigma_j^2)^{(t-1)}) 
	\qquad s.t. \left \| w_j\right \|_0 \le K $ \\
\item $ \sigma_j^{2(t)} = \arg\min_{\sigma_j} Q(w_j^{(t)}, \sigma_j^2) $ \\
\item $ Q(w_j, \sigma_j^2) = -\sum_{n=1}^{N} q^{(t)} (\zeta_j^{(n)}) 
	\log p(y^{(n)} | x^{(n)}, w_j, \sigma_j^2 ) $ \\
\item $ w_j = -\Theta^{-1}_{yy_j}\Theta^T_{xy_j} $ \\
\item $ \sigma^2_j = \Theta^{-1}_{yy_j} $ \\
\item $ \displaystyle \frac{\partial Q (X,Y,\Theta_{xy},\Theta_{yy})}
	{\partial \Theta_{xy}} =	-X^T Y + \sum_i E[x_i y_i^T] $ \\
\item $ \displaystyle \frac{\partial Q (X,Y,\Theta_{xy},\Theta_{yy})}
	{\partial \Theta_{yy}} =-1/2Y^T Y + \sum_i E[y_i y_i^T] $ 
\end{description}

\begin{align*}
\nabla_w Q(w^{(k)}, \sigma^2)_i & = \frac{\partial Q_j}{
	\partial (-\Theta^{-1}_{yy_j}\Theta^T_{xy_j}) } \\
	& = \frac{d Q_j}{
		-\Theta^{-1}_{yy_j}d(\Theta^T_{xy_j})
		 + d(-\Theta^{-1}_{yy_j}) \Theta^T_{xy_j} } \\
	& = \frac{1}{ \frac{-\Theta^{-1}_{yy_j}}{ \frac{\partial Q}
	{\partial(\Theta^T_{xy_j}) }}
		+\frac{\Theta^T_{xy_j}}{ \frac{\partial Q}
		{\partial(-\Theta^{-1}_{yy_j})}} } \\
	& = {\left( - {\left( {(\frac{\partial Q} {\partial\Theta_{xy_j}})}^T
	 \Theta_{yy_j}\right)}^{-1}
		+ {\Theta^T_{yy_j}} {\frac{\partial Q}{\partial\Theta_{yy_j}}
			\Theta_{yy_j}\Theta_{xy_j}^T} \right)}^{-1} \\
\end{align*} 

\begin{itemize}
\item Solution 1 (Within FoBa framework):
	\begin{enumerate}
	\item while not:
		$ \Delta Q(w^{(k)},\sigma^2) \le 0.5\log N_{\phi_j}^{(t)} $ 
	\item Forward:
	\item \qquad Optimize $\phi$: \begin{enumerate}
		\setlength{\itemindent}{4em}
		\item $ \hat{w} = (X^T X)^{-1} X^T Y $
		\item $ \hat{\Theta}_{yy_j} = {\sigma^2_j}^{-1} 
			= {(Y - X \hat{w})}^{-1} $
		\item $ \hat{\Theta}_{xy_j} = 
			- {( \hat{\Theta}_{yy_j} \hat{w} )}^{-1} $
		\end{enumerate}
	\item \qquad Select a feature from unselected feature set 
		\begin{description}
		\setlength{\itemindent}{2em}
		\item{Solution 1.1:} 
			by estimate $\hat{Q}$, then calculate $(\hat{Q}-Q)^T X(v)$ 
			as in current FoBa
		\item{Solution 1.2:} 
			by maximize: 
			$ \lvert \nabla_w Q(w^{(k)}, \sigma^2)_j \rvert $ 
			using $\nabla_w Q(w^{(k)}, \sigma^2)$
		\end{description}	 

	\item Backward: 
	\item \qquad while $ \exists$ feature $i, \Delta Q(w^{(k)}, \sigma^2)_i 
		\le 0.5\log N_{\phi_j}^{(t)} $ ,
		remove the feature.

	\end{enumerate}
\item Solution 2 (Replacing FoBa with gradient descent):
	\begin{enumerate}
	\item Initiate $\phi$ by random sampling
	\item while not:
		$ \Delta Q(w^{(k)},\sigma^2) \le 0.5\log N_{\phi_j}^{(t)} $ 
	\item Optimize $argmin \{ Q(X,Y,\phi)
		+\lambda_1 \lVert \Theta_{xy} \rVert
		+\lambda_2 \lVert \Theta_{yy} \rVert \} $ by
	\item \qquad Find direction using quasi-Newton method with 
		$\partial Q /\partial\Theta_{yy_j}$ and
		 $\partial Q /\partial\Theta_{xy_j}$
	\item \qquad Line search 
	\item Using cross validation to set $\lambda_1$ and $\lambda_2$
	\end{enumerate}
\end{itemize}

\end{document} 
